{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from pyaspeller import YandexSpeller\n",
    "import codecs\n",
    "import json\n",
    "import requests\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from bs4 import BeautifulSoup\n",
    "from multiprocessing.dummy import Pool as ThreadPool \n",
    "from multiprocessing.dummy import Lock as ThreadLock \n",
    "from multiprocessing.dummy import Value as ThreadValue\n",
    "import functools\n",
    "from string import punctuation\n",
    "from re import escape\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"containers2.pkl\",\"rb\") as f:\n",
    "    containers2 = pickle.load(f)\n",
    "with open(\"containers1.pkl\",\"rb\") as f:\n",
    "    containers1 = pickle.load(f)\n",
    "with open(\"containers3.pkl\",\"rb\") as f:\n",
    "    containers3 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e7003baa81f4fd5a45325ec9bdd680e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "word_lems = {}\n",
    "for i in tqdm(containers2.keys()):\n",
    "    for line in containers2[i]:\n",
    "        for word in line.split():\n",
    "            if word not in word_lems.keys():\n",
    "                word_lems[word] = morph.parse(word)[0].normal_form "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "185dfa88d5d441b1b9717f0d1c948764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(containers1.keys()):\n",
    "    for line in containers1[i]:\n",
    "        for word in line.split():\n",
    "            if word not in word_lems.keys():\n",
    "                word_lems[word] = morph.parse(word)[0].normal_form "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519054b02a5e47f1b0a681acdd2cd6fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8114.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(containers3.keys()):\n",
    "    for line in containers3[i]:\n",
    "        for word in line.split():\n",
    "            if word not in word_lems.keys():\n",
    "                word_lems[word] = morph.parse(word)[0].normal_form "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f0418948844acaae29fa2ca7edf1af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08d90956ed6f44b08697616271e4ed52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=653955.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_lemms = set()\n",
    "with codecs.open('Полная парадигма. Морфология. Орфоэпия. Частотность.txt',encoding = 'Windows-1251') as f:\n",
    "    i = 0\n",
    "    for line in tqdm(f):\n",
    "        i+=1\n",
    "        if line[0] != ' ':\n",
    "            for k in line.split('|')[0].split():\n",
    "                all_lemms.add(k)\n",
    "lems = set()\n",
    "for word in tqdm(all_lemms):\n",
    "    lems.add(morph.parse(word)[0].normal_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "323844"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_lems.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "er = set()\n",
    "for word in word_lems.keys():\n",
    "    if word_lems[word] not in lems and not word.isdigit():\n",
    "        counter += 1\n",
    "        er.add(word_lems[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105625"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(er)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14200 objects are processed...ERROR!\n",
      "30330 objects are processed...ERROR!\n",
      "46480 objects are processed...ERROR!\n",
      "62600 objects are processed...ERROR!\n",
      "78710 objects are processed...ERROR!\n",
      "94820 objects are processed...ERROR!\n",
      "105620 objects are processed..."
     ]
    }
   ],
   "source": [
    "def illustration(func):\n",
    "    \"\"\"\n",
    "    Распаралеливание выкачки страниц.\n",
    "    \"\"\"\n",
    "    mutex = ThreadLock()\n",
    "    n_thread = ThreadValue('i',0)\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **argv):\n",
    "        result = func(*args, **argv)\n",
    "        with mutex:\n",
    "            nonlocal n_thread\n",
    "            n_thread.value +=1\n",
    "            if n_thread.value % 10 == 0:\n",
    "                print(f\"\\r{n_thread.value} objects are processed...\",end ='',flush = True)\n",
    "        return result\n",
    "    return wrapper\n",
    "mistakes = []\n",
    "@illustration\n",
    "def change_mistakes(string):\n",
    "    try:\n",
    "        req = requests.post('https://speller.yandex.net/services/spellservice.json/checkText',data = {'text':string})\n",
    "        new_string = string\n",
    "        minus_len = 0\n",
    "        for word in req.json():\n",
    "            new_string = new_string[:word['pos'] - minus_len] + word['s'][0] + new_string[word['pos'] - minus_len + word['len']:]\n",
    "            minus_len += word['len'] - len(word['s'][0]) \n",
    "        n_string = ' '.join([morph.parse(word)[0].normal_form for word in new_string.split()])\n",
    "        error[string] = n_string\n",
    "    except:\n",
    "        print('ERROR!')\n",
    "        mistakes.append(string)\n",
    "error = {}\n",
    "with ThreadPool(20) as pool: \n",
    "    pool.map(change_mistakes, er)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ррахиима', '7ч', 'шагинян', 'января4', 'приколыфнаф', 'бойли']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_mistakes('бойли')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42d33224f1f4788939a0e90b866ddc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_docs = {}\n",
    "for i in tqdm(containers2.keys()):\n",
    "    lines = []\n",
    "    for line in containers2[i]:\n",
    "        tmp = ''\n",
    "        for word in line.split():\n",
    "            if word_lems[word] in error.keys() :\n",
    "                tmp += error[word_lems[word]] + ' '\n",
    "            else:\n",
    "                tmp += word_lems[word] + ' '\n",
    "        lines.append(tmp)\n",
    "    new_docs[i] = lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329ab1e70fa748f4ad31187752de4abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(containers1.keys()):\n",
    "    lines = []\n",
    "    for line in containers1[i]:\n",
    "        tmp = ''\n",
    "        for word in line.split():\n",
    "            if word_lems[word] in error.keys() :\n",
    "                tmp += error[word_lems[word]] + ' '\n",
    "            else:\n",
    "                tmp += word_lems[word] + ' '\n",
    "        lines.append(tmp)\n",
    "    new_docs[i] = lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e1cb9e3846499aaab7bf3afadc2a1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=8114.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(containers3.keys()):\n",
    "    lines = []\n",
    "    for line in containers3[i]:\n",
    "        tmp = ''\n",
    "        for word in line.split():\n",
    "            if word_lems[word] in error.keys() :\n",
    "                tmp += error[word_lems[word]] + ' '\n",
    "            else:\n",
    "                tmp += word_lems[word] + ' '\n",
    "        lines.append(tmp)\n",
    "    new_docs[i] = lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('containers.pkl','wb') as f:\n",
    "    pickle.dump(new_docs,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38114"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_docs.items())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
